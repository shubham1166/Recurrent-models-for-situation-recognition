{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "situation_prediction_network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NazFW4cIMFA",
        "colab_type": "text"
      },
      "source": [
        "# SHUBHAM SHARMA\n",
        "## IIT BOMBAY\n",
        "This code is for prediction of predictions after we are done with *fusion network*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdXOiYhmILaT",
        "colab_type": "code",
        "outputId": "08aeef80-1791-4e7e-9262-eb601c44cdc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "#For Deep learning\n",
        "from keras.layers import LSTM, TimeDistributed , Dense, RepeatVector, Conv2D, MaxPooling2D, Input, BatchNormalization, Flatten, Embedding, Reshape, concatenate\n",
        "import keras\n",
        "from keras import callbacks \n",
        "from keras.models import Model\n",
        "from keras.optimizers import adam,Adagrad,SGD\n",
        "\n",
        "##\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc-3tLwvLnD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_network(width, height, depth, verb_length = 1, num_verbs = 50, hidden_layer = 3500, encoding_nodes=4096, weightsPath=None):\n",
        "  \n",
        "  bn_flag = True\n",
        "  inputs_to_vgg = Input((width, height , depth))\n",
        "  conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs_to_vgg)\n",
        "  conv1 = BatchNormalization(axis = -1)(conv1,training=bn_flag)\n",
        "  conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "  conv1 = BatchNormalization(axis= -1)(conv1,training=bn_flag)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  ##\n",
        "  conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "  conv2 = BatchNormalization(axis = -1)(conv2,training=bn_flag)\n",
        "  conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "  conv2 = BatchNormalization(axis= -1)(conv2,training=bn_flag)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "  ##\n",
        "  conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "  conv3 = BatchNormalization(axis = -1)(conv3,training=bn_flag)\n",
        "  conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "  conv3 = BatchNormalization(axis = -1)(conv3,training=bn_flag)\n",
        "  conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "  conv3 = BatchNormalization(axis = -1)(conv3,training=bn_flag)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "  ##\n",
        "  conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "  conv4 = BatchNormalization(axis = -1)(conv4,training=bn_flag)\n",
        "  conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "  conv4 = BatchNormalization(axis = -1)(conv4,training=bn_flag)\n",
        "  conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "  conv4 = BatchNormalization(axis = -1)(conv4,training=bn_flag)\n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "  ##\n",
        "  conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "  conv5 = BatchNormalization(axis = -1)(conv5,training=bn_flag)\n",
        "  conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "  conv5 = BatchNormalization(axis = -1)(conv5,training=bn_flag)\n",
        "  conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "  conv5 = BatchNormalization(axis = -1)(conv5,training=bn_flag)\n",
        "  pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
        "  ##\n",
        "  Y = Flatten()(pool5)\n",
        "  Y = Dense(hidden_layer, activation='relu')(Y)\n",
        "  Y = Dense(hidden_layer, activation='relu')(Y)\n",
        "  Y = Dense(hidden_layer, activation='relu')(Y)\n",
        "  Y = Reshape((1,hidden_layer))(Y)\n",
        "\n",
        "  ####################################################################################################\n",
        "  # Y is the output from the VGG network. Now let us make an output from the verb and concatenate them \n",
        "  input_verb = Input([verb_length])\n",
        "  Z = Embedding(num_verbs, hidden_layer)(input_verb)\n",
        "  \n",
        "  input_to_lstm = concatenate([Z , Y],axis = 1)\n",
        "  encoder = LSTM(encoding_nodes)(input_to_lstm)\n",
        "  \n",
        "  L = RepeatVector(39)(encoder)\n",
        "  L = LSTM(2310 , return_sequences = True)(L)\n",
        "  out = TimeDistributed(Dense(2310, activation = 'softmax'))(L)\n",
        "  \n",
        "\n",
        "  model = Model(inputs=[inputs_to_vgg , input_verb], outputs=[out])\n",
        "  \n",
        "  if weightsPath is not None:\n",
        "    model.load_weights(weightsPath)\n",
        "    \n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-gac9x5D7H_",
        "colab_type": "code",
        "outputId": "7794237e-8aff-463a-d235-c36e09d96f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfk0Km1sMzEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_images = np.load('gdrive/My Drive/Situation_recognition/data/X.npy')\n",
        "X_verbs = np.load('gdrive/My Drive/Situation_recognition/data/Y_verbs.npy')\n",
        "Y = np.load('gdrive/My Drive/Situation_recognition/data/Y_nouns_categorical.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF1zEO9pkNhM",
        "colab_type": "code",
        "outputId": "a2ab4f56-934a-41c8-d8a1-aa4b4be75c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = prediction_network(width = 256, height = 256, depth = 3, weightsPath='gdrive/My Drive/Situation_recognition/situation2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 64) 36928       batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 64) 256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 128, 128, 128 512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 128 147584      batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 256)  1024        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 256)  590080      batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 64, 64, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 256)  590080      batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 256)  1024        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 512)  2048        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 512)  2359808     batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 512)  2048        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 512)  2359808     batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 512)  2048        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 512)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 512)  2359808     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 512)  2048        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 512)  2359808     batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 512)  2359808     batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 512)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 32768)        0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 3500)         114691500   flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 3500)         12253500    dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 3500)         12253500    dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 3500)      175000      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 3500)      0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 2, 3500)      0           embedding_1[0][0]                \n",
            "                                                                 reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 4096)         124469248   concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_1 (RepeatVector)  (None, 39, 4096)     0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 39, 2310)     59200680    repeat_vector_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 39, 2310)     5338410     lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 343,113,422\n",
            "Trainable params: 343,104,974\n",
            "Non-trainable params: 8,448\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvQ5rI5JIFX4",
        "colab_type": "code",
        "outputId": "7583e149-b813-46d5-c48e-57baa7b652f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "path2save = 'gdrive/My Drive/Situation_recognition/situation2.h5'\n",
        "modelCheck = callbacks.ModelCheckpoint(path2save, monitor='loss', verbose=0, mode='auto')\n",
        " \n",
        "opt = Adagrad(lr=1e-7)\n",
        "#Set the compiler parameter for the training\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"categorical_accuracy\"],sample_weight_mode='auto')\n",
        "print (\"Training the Model...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Training the Model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCHZBHyFIywz",
        "colab_type": "code",
        "outputId": "4c754611-f9d7-4a30-c0f0-952110f442b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "history = model.fit([X_images , X_verbs] , Y, batch_size=32, epochs=500, verbose=1, callbacks= [modelCheck], shuffle=True)#,validation_data = (x_test , y_test)\n",
        "print (\"Dumping Weights to file...\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/500\n",
            "13379/13379 [==============================] - 274s 20ms/step - loss: 0.1585 - categorical_accuracy: 0.9723\n",
            "Epoch 2/500\n",
            "11552/13379 [========================>.....] - ETA: 35s - loss: 0.1597 - categorical_accuracy: 0.9722"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCLaqB9HufQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}